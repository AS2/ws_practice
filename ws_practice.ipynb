{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qun-iZnsUudv"
      },
      "source": [
        "# Зимний университет 2024. Введение в Deep learning.\n",
        "\n",
        "Лабораторная состоит из гайда по методам глубинного обучения (Deep Learning) на Python и 3x заданий:\n",
        "\n",
        "* [Задание 1](#Задание-1.) - реализация нейросети для классификации рукописных цифр.\n",
        "\n",
        "* [Задание 2](#Задание-2.) - выбор подходящих аугментаций.\n",
        "\n",
        "* [Задание 3](#Задание-3.) - реализация нейросети для устранения шумов.\n",
        "\n",
        "Задания расположены в порядке усложнения. Среди них вы должны выполнить 1 задания обязательно, а также 2 и 3 задания по желанию. По заданию 1 на основе качества обучения сети будет составляться рейтинг: чем меньше значение функции ошибки на валидационной выборке, тем выше у вас место. Оставшееся задания можно сделать при сдаче первого - они дадут вам дополнительные баллы: второе - 3 балла, третье - 5 баллов.\n",
        "\n",
        "Итоговый балл считается следующим образом: рассчитывается балл за первое задание (= кол-во сдавших - местро в рейтинге + 1), к нему добавляются баллы за доп задания.\n",
        "\n",
        "По завершению каждого задания - подзывайте преподавателя для демонстрации работы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDMPix9lUudw"
      },
      "source": [
        "*В этом ноутбуке изначально опущены результаты исполнения кода. Рекомендуется запускать (Shift+Enter) ячейки по мере просмотра документа*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8Tij-oeUudx"
      },
      "source": [
        "#### Используемые модули\n",
        "\n",
        "Обновим пакетный менеджер pip, чтобы корректно уставить необходимые модули:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fl2X9DdsUudx"
      },
      "outputs": [],
      "source": [
        "# При необходимости добавляйте опцию --user\n",
        "!pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmiSoA3rUud0"
      },
      "source": [
        "Подключим модули, которые пригодятся в мини-лабораторной."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_q-C6gUQUud0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "import os\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.random import set_seed as set_random_seed\n",
        "from keras import Model, Input\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.datasets import fashion_mnist, mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import (Conv2D, MaxPooling2D, Flatten, Reshape, GlobalMaxPooling2D,\n",
        "                          Activation, Dense, BatchNormalization, UpSampling2D )\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import json\n",
        "import os\n",
        "\n",
        "\n",
        "def add_to_answer(task, answer_dict):\n",
        "    \"\"\"\n",
        "    Добавление ответа на задание в файл с ответами.\n",
        "    \"\"\"\n",
        "    filename = \"answers.json\"\n",
        "\n",
        "    answers_data = {}\n",
        "    if os.path.exists(filename):\n",
        "        with open(filename, 'r') as f:\n",
        "            old_answers_data = json.load(f)\n",
        "        answers_data.update(old_answers_data)\n",
        "\n",
        "    answers_data[task] = answer_dict\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(answers_data, f, indent=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfiFUt8sUud0"
      },
      "source": [
        "### Нейронные сети\n",
        "\n",
        "Если вы планируете использовать нейронные сети, имеет смысл ознакомиться с [этим](https://github.com/abidlabs/AtomsOfDeepLearning/blob/master/Atomic%20Experiments%20in%20Deep%20Learning.ipynb) ноутбуком (но для выполнения лабораторной это не обязательно).\n",
        "\n",
        "С нейронными сетями чаще всего гораздо сложнее работать, чем с градиентным бустингом: приходится подбирать архитектуру, настраивать огромное число гиперпараметров; нет возможности узнать, по какому принципу сеть находит ответ. Однако есть ситуации, в которых нейронные сети просто не имеют адекватно работающих альтернатив:\n",
        "* обработка изображений, видео - Convolutional NN;\n",
        "* построение эмбеддинга с учителем и без учителя - AutoEncoder, Siamese NN;\n",
        "* работа с последовательностями, в том числе генерирование - Recurrent NN и **Transformer**;\n",
        "* создание генеративных моделей без учителя - Generative Adversarial Networks, Noise Conditional Score Network, и т.д.\n",
        "\n",
        "Большая часть преимуществ достигается из-за возможности точно управлять целью обучения с помощью функции потерь, а также возможности использовать части обученной сети для решения новой задачи. Например, научив сеть предсказывать корректность словосочетания, можно применять найденный сетью способ кодирования слов для нахождения семантической близости.\n",
        "\n",
        "#### Кратко о фреймворках\n",
        "\n",
        "Есть несколько актуальных на данный момент фреймворков для работы с нейронными сетями:\n",
        "* TensorFlow - построение статических графов вычислений, автоматический вывод градиентов, блоки для построения сетей. Имеет высокий \"порог вхождения\". С версии `2.0` поддерживает т.н. eager-вычисления, т.е. динамические графы. Обратная совместимость с версиями `1.*` частично отсутствует и может потреобвать переписывания части кода;\n",
        "* PyTorch - построение динамических графов вычислений, лёгкий перенос вычислений на GPU (требует изменения кода);\n",
        "* Keras - построение нейронных сетей из блоков. Вычисления производятся с помощью одного из низкоуровневых фреймворков (backend): TensorFlow, CNTK, Theano и др.\n",
        "\n",
        "Если не требуется реализовывать принципиально новый алгоритм машинного обучения, внедрять наиболее современные механизмы и т.д., проще всего использовать Keras.\n",
        "\n",
        "Для некоторых архитектур нейронных сетей пишут профильные оптимизированные решения (например, для [YOLO](https://pjreddie.com/darknet/yolo/) - алгоритма быстрого поиска объектов на изображениях реализована низкоуровневая поддержка в библиотеке [Darknet](https://github.com/pjreddie/darknet)). Фреймворки вроде TensorFlow, хоть и обеспечивающие работу с несколькими GPU в кластерах, часто проигрывают по производительности узкопрофильным решениям. На практике, если применяют TensorFlow, как правило используют [оптимизаторы](https://developer.nvidia.com/tensorrt) для ускорения инференса, а для этапа тренировки тратят приличное число ресурсов.\n",
        "\n",
        "\n",
        "#### Пример\n",
        "\n",
        "Воспользуемся фреймворком `Keras`, который работает на `Tensorflow`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PG1rk4dgUud1"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6s2ZIt7Uud1"
      },
      "source": [
        "### Нейронные сети для обработки изображений"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbiev2-4Uud1"
      },
      "source": [
        "Загрузим датасет fashion mnist, содержащий изображения одежды (grayscale 28x28) 10 различных классов:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVh60XqSUud1"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "classes = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "# Переводим цвета из диапазона [0, 255] к диапазону [0, 1]\n",
        "train_images = train_images / 255.0\n",
        "test_images  = test_images / 255.0\n",
        "# Переводим числовые метки в категориальные - вместо номера класса от 0 до 9 будем использовать векторы\n",
        "# из 10 элементов, где все нули, кроме единицы на i-ой позиции для i-го класса.\n",
        "# Такой подход позволяет избежать негативных эффектов при обучении, т.к. между классами нет строгого линейного порядка,\n",
        "# как в случае с числами от 0 до 9.\n",
        "train_vectors = to_categorical(train_labels)\n",
        "test_vectors = to_categorical(test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEezMzrwUud2"
      },
      "source": [
        "Рассмотрим пример пострения нейронной сети из 2 слоев свертки, понижений размерности и вывода классов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLA1KTGEUud2"
      },
      "outputs": [],
      "source": [
        "np.random.seed(1)\n",
        "set_random_seed(1)\n",
        "\n",
        "def build_model():\n",
        "    image_model = Sequential()\n",
        "\n",
        "    image_model.add(Reshape((28, 28, 1), input_shape=(28, 28)))\n",
        "    image_model.add(Conv2D(3, kernel_size=(3, 3), strides=(1, 1), activation='relu'))\n",
        "    image_model.add(BatchNormalization())\n",
        "    image_model.add(MaxPooling2D())\n",
        "\n",
        "    image_model.add(Conv2D(3, kernel_size=(3, 3), strides=(1, 1), activation='relu'))\n",
        "    image_model.add(BatchNormalization())\n",
        "    image_model.add(MaxPooling2D())\n",
        "    image_model.add(Flatten())\n",
        "\n",
        "    image_model.add(Dense(4, activation='relu'))\n",
        "    image_model.add(Dense(10, activation='softmax'))\n",
        "    image_model.compile(optimizer='adam',\n",
        "                        loss='categorical_crossentropy',\n",
        "                        metrics=['accuracy'])\n",
        "    # Функция должна возвращать построенную и скомпилированную модель\n",
        "    return image_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoHJBbfkUud2"
      },
      "source": [
        "Рассмотрим параметры обучения:\n",
        "* `epochs` - число эпох. Эпоха заканчивается, когда сеть увидела все примеры тренировочного множества;\n",
        "* `batch_size` - размер мини-батча. В [SGD](http://www.machinelearning.ru/wiki/index.php?title=Стохастический_градиентный_спуск) элементы обучающей выборки разбиваются на группы (мини-батчи) и функция потерь, вместе с её производной, рассчитывается на мини-батчах. Веса обновляются после просмотра каждого мини-батча. Вычислительно выгодней, чтобы мини-батч был достаточно большого размера, поскольку в таком случае данные будут обрабатываться параллельно;\n",
        "* `validation_data` - данные для построения кривой ошибки на валидационных данных \"Validation loss\".\n",
        "\n",
        "По графику функции потерь (loss) можно судить о том, имеет ли смысл обучать сеть большее число итераций.\n",
        "\n",
        "Посмотрим на качество полученной сети:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qHogSJ0Uud2"
      },
      "outputs": [],
      "source": [
        "n_epochs = 10\n",
        "image_model = build_model()\n",
        "\n",
        "history = image_model.fit(\n",
        "    train_images, train_vectors,\n",
        "    epochs=n_epochs,\n",
        "    # число примеров, на которых считается градиент:\n",
        "    batch_size=32,\n",
        "    validation_data=(test_images, test_vectors),\n",
        "    verbose=True,  # Отключаем вывод, чтобы не перегружать ноутбук лишним выводом\n",
        ")\n",
        "\n",
        "plt.plot(range(n_epochs), (history.history['loss']), c='b')\n",
        "plt.plot(range(n_epochs), (history.history['val_loss']), c='g')\n",
        "plt.legend(['Train Loss', 'Validation loss'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видно, что точность крайне мала - необходимо что-то сделать с кодом сети. В следующем задании предлагается Вам возможность реализовать собственную сеть и поучаствовать с другими учениками в конкурсе за первое место в точности модели."
      ],
      "metadata": {
        "id": "wKcmeN6KWLhi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XYDQnFaUud3"
      },
      "source": [
        "#### Задание 1.\n",
        "\n",
        "Измените параметры свёрточной сети / параметры обучения (метода `fit`), чтобы повысить качество (accuracy) на **тестовых данных** до **0.87**.\n",
        "\n",
        "Если Вы перезапустили ноутбук, надо заново загрузить датасет, выполнив начальную ячейку с кодом в разделе [Нейронные сети для обработки изображений](#Нейронные-сети-для-обработки-изображений)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C315QsJ8Uud3"
      },
      "outputs": [],
      "source": [
        "np.random.seed(1)\n",
        "set_random_seed(1)\n",
        "\n",
        "# Входной слой: его менять НЕ НАДО.\n",
        "classification_model = Sequential()\n",
        "classification_model.add(Reshape((28, 28, 1), input_shape=(28, 28)))\n",
        "\n",
        "# далее input_shape указывать не обязательно\n",
        "# Постройте свою модель на примере выше. Следует добавлять слои свертки, пулинг и нормализации признаков как приведено в этом комментарии ниже.\n",
        "# classification_model.add(Conv2D(*filters_cnt*,\n",
        "#                         kernel_size=*kernel_size*,\n",
        "#                         strides=*strides (промежутки между элементами ядра)*,\n",
        "#                         activation=*функция активации, например - 'relu'*,\n",
        "#                         ))\n",
        "# или\n",
        "# classification_model.add(BatchNormalization())\n",
        "# или\n",
        "# classification_model.add(MaxPooling2D())\n",
        "\n",
        "\n",
        "classification_model.add(...)\n",
        "classification_model.add(...)\n",
        "classification_model.add(...)\n",
        "# .... и еще слои, сколько посчитаете нужным\n",
        "\n",
        "\n",
        "# Слой ниже (и последующие слои) менять НЕ надо\n",
        "classification_model.add(Flatten(name='flatten'))\n",
        "classification_model.add(Dense(4, activation='relu'))\n",
        "classification_model.add(Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbbwVo55Uud3"
      },
      "outputs": [],
      "source": [
        "classification_model.compile(optimizer='adam',\n",
        "                             loss='categorical_crossentropy',\n",
        "                             metrics=['accuracy'])\n",
        "\n",
        "classification_model.fit(train_images, train_vectors, epochs=5, batch_size=128,\n",
        "                         validation_data=(test_images, test_vectors))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPyQPPPCUud3"
      },
      "outputs": [],
      "source": [
        "def evaluate_model_for_task_2(model):\n",
        "    test_acc = accuracy_score(test_labels, np.argmax(model.predict(test_images), axis=-1))\n",
        "    print(f\"Качество: {test_acc}\")\n",
        "    print(\"Тест на качество {}\".format(\"НЕ пройден :(\" if 0.87 > test_acc else \"пройден :)\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d34eCpGhUud3"
      },
      "source": [
        "Вызовите функцию `evaluate_model_for_task_2`, передав ей обученную модель, чтобы увидеть качество этой модели. При сдаче задания качество должно быть не ниже **0.88**.\n",
        "\n",
        "Не забудьте сохранить модель, выполнив ячейки ниже.\n",
        "\n",
        "_Примечание: модель, полученная в ходе выполнения этого задания, будет использована далее, поэтому важно, чтобы она называлась_ `classification_model`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jUrvwQtUud3",
        "outputId": "6530c645-33a0-48e7-f197-9560bedc8371"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Качество: 0.8831\n",
            "Тест на качество пройден :)\n"
          ]
        }
      ],
      "source": [
        "#  classification_model = best_model\n",
        "evaluate_model_for_task_2(classification_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jzGBwsAUud4"
      },
      "source": [
        "Модель понадобится в следующем задании, поэтому сохраним её"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ve54YOmUud4"
      },
      "outputs": [],
      "source": [
        "second_task_saved_model = os.path.join(\"models\", \"task_2_weights.h5\")\n",
        "# Создаём папку, куда сохраним результаты, если папки ещё нет\n",
        "Path(\"models\").mkdir(parents=True, exist_ok=True)\n",
        "classification_model.save(second_task_saved_model)\n",
        "\n",
        "add_to_answer(\n",
        "    \"task_2\",\n",
        "    {\n",
        "        \"model_path\": second_task_saved_model,\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiVkZ9WDUud4"
      },
      "source": [
        "---\n",
        "\n",
        "Посмотрим как выглядит предсказание:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PI3Fb5FUud4"
      },
      "outputs": [],
      "source": [
        "np.random.seed(123456)\n",
        "test_ind = np.random.randint(test_images.shape[0])\n",
        "test_image = test_images[test_ind]\n",
        "test_vector = test_vectors[test_ind]\n",
        "predicted_test_vector = classification_model.predict(test_image[np.newaxis]).reshape((10,))\n",
        "\n",
        "plt.imshow(test_image, cmap='gray')\n",
        "plt.title('Тестовое изображение')\n",
        "plt.figure()\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(17, 4))\n",
        "ax[0].bar(range(10), test_vector, tick_label=classes)\n",
        "ax[1].bar(range(10), predicted_test_vector, tick_label=classes)\n",
        "for i, title in enumerate(['Правильный вектор классов', 'Предсказанный вектор']): ax[i].set_title(title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RR4t68z4Uud4"
      },
      "source": [
        "Получим предсказания для первых 100 изображений:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "UXMlNBsLUud4"
      },
      "outputs": [],
      "source": [
        "%time\n",
        "predicted_vectors = classification_model.predict(test_images[:100]).reshape((100, 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxdJsEM7Uud5"
      },
      "source": [
        "Посмотрим на каких изображениях сеть ошибается:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "linrqVKbUud5"
      },
      "outputs": [],
      "source": [
        "predicted_labels = np.argmax(predicted_vectors, axis=1)  # предсказанные индексы классов - где верояность наибольшая\n",
        "\n",
        "pred = test_labels[:100] != predicted_labels\n",
        "misclassified_images = test_images[:100][pred]\n",
        "misclassified_correct = test_labels[:100][pred]\n",
        "misclassified_predicted = predicted_labels[:100][pred]\n",
        "\n",
        "cm = confusion_matrix(test_labels[:100], predicted_labels[:100])\n",
        "plt.imshow(cm, interpolation='nearest')\n",
        "plt.xticks(range(10), classes, rotation=90)\n",
        "plt.yticks(range(10), classes)\n",
        "plt.colorbar()\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.figure()\n",
        "\n",
        "fig, ax = plt.subplots(2, 6, figsize=(15, 4))\n",
        "for i in range(2 * 6):\n",
        "    ax.flatten()[i].imshow(misclassified_images[i], cmap='gray')\n",
        "    ax.flatten()[i].axis('off')\n",
        "    ax.flatten()[i].set_title(f\"{classes[misclassified_predicted[i]]} / {classes[misclassified_correct[i]]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3IombeQUud5"
      },
      "source": [
        "---\n",
        "\n",
        "## Аугментация\n",
        "\n",
        "Часто доступные на этапе обучения размеченные данные оказываются смещёнными, не целиком покрывающими допустимое для данной задачи распределение входных данных.\n",
        "Также, при использовании нейронных сетей с большим числом параметров, на этапе обучения необходимо большое число различных данных, чтобы модель не деградировала до \"табличной функции\", запоминая все входные данные.\n",
        "\n",
        "Для борьбы с обеими проблемами хорошо подходит подход искусственного расширения обучающего набора данных – аугментация. Идея заключается в применении случайных трансформаций к каждому отдельному изображению, при сохранении меток классов. Таким образом можно получить датасет произвольного размера и добиться от нейронной сети определённых свойств (разумеется, для фиксированного, ограниченного распределения входных данных), например: инвариантности к повороту объекта – за счёт обучения на всевозможных поворотах входных изображений.\n",
        "\n",
        "Важно, что выбор набора трансформаций и распределений из которых генерируются их параметры, специфичен для каждой задачи. Например, при классификации деревьев не разумно выполнять повороты на $\\pi$, поскольку известно, что деревья всегда растут снизу вверх.\n",
        "\n",
        "---\n",
        "\n",
        "Будем загружать датасет из GoogleDisk, воспользуемся библиотекой `googledrivedownloader`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-6gtf-6Uud5"
      },
      "source": [
        "Скачаем файлы с данными:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbE9GQx-Uud5"
      },
      "outputs": [],
      "source": [
        "ids_to_file_names = {\n",
        "    '1iFK4-fCqs8l5lWmYnUYlkv28GDb43FUv': 'fashion_images.npy',\n",
        "    '15NUcK_Pg4iEUttK1XiG0SonJaEbaaVnI': 'fashion_labels.npy',\n",
        "    '1AXtbCz3EE2xVuUrGgEco7a-lMh8Vqm0o': 'val_fashion_images.npy',\n",
        "    '1fk1mZxBLRryWp4IoLHRr5IwiaKy4WL_Y': 'val_fashion_labels.npy',\n",
        "    '1tWy1d9lkrCzkiSZBlfd1G6YV4sZ7pNt4': 'test_fashion_images.npy',\n",
        "}\n",
        "\n",
        "# Файлы будем загружать и сохранять в папку data\n",
        "for _id in ids_to_file_names:\n",
        "    ids_to_file_names[_id] = os.path.join(\"data\", ids_to_file_names[_id])\n",
        "\n",
        "# Создадим папку data, если её ещё нет\n",
        "Path(\"data\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "for file_id in ids_to_file_names:\n",
        "    # Качаем файл только если он ещё не скачан\n",
        "    if not os.path.isfile(ids_to_file_names[file_id]):\n",
        "        gdd.download_file_from_google_drive(file_id=file_id,\n",
        "                                            dest_path=os.path.join('.', ids_to_file_names[file_id]),\n",
        "                                            unzip=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOhJC-EtUud6"
      },
      "source": [
        "Загрузим данные – изображения 64x64 с цветным шумом и случайно аффинно трансформированными снимками одежды:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8aI6j31Uud6"
      },
      "outputs": [],
      "source": [
        "def load_from_data(fname):\n",
        "    return np.load(os.path.join(\"data\", fname))\n",
        "\n",
        "fashion_images = load_from_data(\"fashion_images.npy\")\n",
        "fashion_labels = load_from_data(\"fashion_labels.npy\")\n",
        "\n",
        "val_fashion_images = load_from_data(\"val_fashion_images.npy\")\n",
        "val_fashion_labels = load_from_data(\"val_fashion_labels.npy\")\n",
        "\n",
        "test_fashion_images = load_from_data(\"test_fashion_images.npy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLGQrx23Uud6"
      },
      "source": [
        "В качестве тренировочного и валидационного датасета даны изображения и метки (вектора вероятностей классов одежды), в качестве тестового – только изображения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PjSIpaEUud6"
      },
      "source": [
        "Ниже дана модель, гиперпараметры которой (количества каналов, размеры ядер, функции активации, архитектуру и т.п.) менять **нельзя**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzP-lK-yUud6"
      },
      "outputs": [],
      "source": [
        "def make_fashion_model():\n",
        "    imodel = Sequential()\n",
        "    imodel.add(Reshape((64, 64, 3), input_shape=(64, 64, 3)))\n",
        "    imodel.add(Conv2D(4, kernel_size=(3, 3), strides=(1, 1),\n",
        "                         activation='relu', padding='same'))\n",
        "    imodel.add(BatchNormalization())\n",
        "    imodel.add(MaxPooling2D())\n",
        "    imodel.add(Conv2D(8, kernel_size=(3, 3), strides=(1, 1),\n",
        "                         activation='relu', padding='same'))\n",
        "    imodel.add(BatchNormalization())\n",
        "    imodel.add(MaxPooling2D())\n",
        "    imodel.add(Conv2D(16, kernel_size=(3, 3), strides=(1, 1),\n",
        "                         activation='relu', padding='same'))\n",
        "    imodel.add(BatchNormalization())\n",
        "    imodel.add(MaxPooling2D())\n",
        "    imodel.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1),\n",
        "                         activation='relu', padding='same'))\n",
        "    imodel.add(BatchNormalization())\n",
        "    imodel.add(MaxPooling2D())\n",
        "    imodel.add(Conv2D(64, kernel_size=(3, 3), strides=(1, 1),\n",
        "                         activation='relu', padding='same'))\n",
        "    imodel.add(BatchNormalization())\n",
        "    imodel.add(MaxPooling2D())\n",
        "    imodel.add(Conv2D(128, kernel_size=(3, 3), strides=(1, 1),\n",
        "                         activation='relu', padding='same'))\n",
        "    imodel.add(BatchNormalization())\n",
        "    imodel.add(Flatten())\n",
        "\n",
        "    iclf = Sequential()\n",
        "    iclf.add(imodel)\n",
        "    iclf.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    iclf.compile(optimizer='adam',\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "    return iclf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPhz5Mj4Uud-"
      },
      "source": [
        "---\n",
        "\n",
        "#### Задание 2 (дополнительное).\n",
        "\n",
        "**Внимание!** Это задание повышенной сложности, за его решение даётся 2.5 балла, выполнять его необязательно.\n",
        "\n",
        "Найти такие параметры аугментации (ниже), чтобы качество классификации (accuracy) на **тестовых** данных было **не ниже 0.6**.\n",
        "\n",
        "*Настоятельно рекомендуется сначала внимательно изучить обучающую и тестовую выборки, а не подбирать параметры случайным образом.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Y0XWnFfUud_"
      },
      "outputs": [],
      "source": [
        "train_fashion_images = fashion_images.copy()\n",
        "# здесь можно сделать предварительную обработку всего обучающего датасета\n",
        "train_fashion_labels = fashion_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVsqybNqUud_"
      },
      "outputs": [],
      "source": [
        "# здесь следует изменить параметры аугментации (параметры ImageDataGenerator):\n",
        "print(train_fashion_images[0])\n",
        "aug_params = {  # Параметры задаём сначала в словаре, чтобы их потом сохранить\n",
        "    \"featurewise_center\": False,  # Bool: False/True\n",
        "    \"samplewise_center\": False,  # Bool: False/True\n",
        "    \"featurewise_std_normalization\": False,  # Bool: False/True\n",
        "    \"samplewise_std_normalization\": False,  # Bool: False/True\n",
        "    \"width_shift_range\": 0.0, # integer pos number, but in float type (idk)\n",
        "    \"height_shift_range\": 0.0, # integer pos number, but in float type (idk)\n",
        "    \"brightness_range\": None, # No need to change\n",
        "    \"shear_range\": 0,\n",
        "    \"zoom_range\": 0, # Float pos number\n",
        "    \"channel_shift_range\": 0,\n",
        "    \"fill_mode\": 'nearest',\n",
        "    \"cval\": 0.0,\n",
        "    \"horizontal_flip\": False,  # Bool: False/True\n",
        "    \"vertical_flip\": False,  # Bool: False/True\n",
        "    \"rescale\": None,\n",
        "}\n",
        "\n",
        "aug = ImageDataGenerator(**aug_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1TjImAJUud_"
      },
      "source": [
        "Из параметров обучения можно менять `batch_size` и `epochs`, но использовать можно не больше 200 эпох.\n",
        "\n",
        "При желании можно разобраться в механизме callback'ов и передать в `fit` дополнительные параметры для автоматического сохранения весов модели к состоянию на \"лучшей\" итерации обучения (лучшей с точки зрения качества на валидационных данных), но это делать не обязательно."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "0inlRQKdUud_"
      },
      "outputs": [],
      "source": [
        "fit_params = {\n",
        "    \"batch_size\": 32,\n",
        "    \"epochs\": 200,\n",
        "}\n",
        "\n",
        "fashion_clf = make_fashion_model()\n",
        "\n",
        "aug.fit(train_fashion_images)\n",
        "gen = aug.flow(train_fashion_images, train_fashion_labels,\n",
        "               batch_size=fit_params[\"batch_size\"])\n",
        "\n",
        "print(gen[0][0])\n",
        "\n",
        "hist = fashion_clf.fit(\n",
        "    gen,\n",
        "    steps_per_epoch=len(train_fashion_images) // fit_params[\"batch_size\"],\n",
        "    validation_data=(val_fashion_images, val_fashion_labels),\n",
        "    **fit_params,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_z27zRbUud_"
      },
      "outputs": [],
      "source": [
        "def plot_accuracy(history):\n",
        "    acc = 'acc' if 'acc' in history else 'accuracy'\n",
        "    val_acc = 'val_' + acc\n",
        "\n",
        "    plt.plot(range(len(history[acc])), history[acc], color='b')\n",
        "    plt.plot(range(len(history[val_acc])), history[val_acc], color='g')\n",
        "\n",
        "    return hist.history[val_acc][-1]\n",
        "\n",
        "plot_accuracy(hist.history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gj6ZuUGUUueA"
      },
      "source": [
        "Для проверки сохраняются веса сети:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkJG3Ke-UueA"
      },
      "outputs": [],
      "source": [
        "aug_saved_model = os.path.join(\"models\", \"task_4_weights.h5\")\n",
        "# Создаём папку, куда сохраним результаты, если папки ещё нет\n",
        "Path(\"models\").mkdir(parents=True, exist_ok=True)\n",
        "fashion_clf.save(aug_saved_model)\n",
        "\n",
        "add_to_answer(\n",
        "    \"task_4\",\n",
        "    {\n",
        "        \"model_path\": aug_saved_model,\n",
        "        \"fit_params\": fit_params,\n",
        "        \"aug_params\": aug_params,\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNDjnfmnUueB"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Задание 3.\n",
        "\n",
        "**Задание повышенной сложности!**\n",
        "Необходимл реализовать код шумоподавляющего автокодировщика.\n",
        "\n",
        "Для начала загрузим данные датасета MNIST."
      ],
      "metadata": {
        "id": "T4yKr5gEd3iV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "assert x_train.shape == (60000, 28, 28)\n",
        "assert x_test.shape == (10000, 28, 28)\n",
        "assert y_train.shape == (60000,)\n",
        "assert y_test.shape == (10000,)"
      ],
      "metadata": {
        "id": "dM5Q9QwzeKhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Метки классов можно отбросить - для создания модели удаления шумов они не нужны. Сохраним как y_train и y_test точные снимки рукописных цифр, а в x_train и x_test добавим пуассоновские шумы."
      ],
      "metadata": {
        "id": "9QaNzdvVfPYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train, y_test = x_train.astype(\"float32\") / 255.0, x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "x_train = np.sum(\n",
        "                        [\n",
        "                            x_train.astype(\"float32\") / 255.0,\n",
        "                            (np.random.poisson(64,x_train.shape[0] * x_train.shape[1] * x_train.shape[2]).reshape(x_train.shape)) / 255.0,\n",
        "                        ],\n",
        "                        axis=0,\n",
        "                    ).astype(\"float32\")\n",
        "\n",
        "x_test = np.sum(\n",
        "                        [\n",
        "                            x_test.astype(\"float32\") / 255.0,\n",
        "                            (np.random.poisson(64,x_test.shape[0] * x_test.shape[1] * x_test.shape[2]).reshape(x_test.shape)) / 255.0,\n",
        "                        ],\n",
        "                        axis=0,\n",
        "                    ).astype(\"float32\")\n",
        "\n",
        "x_train, x_test = x_train / np.amax(x_train), x_test / np.amax(x_test)"
      ],
      "metadata": {
        "id": "qvX9eLPOffVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим как теперь выглядят шумные и точные данные"
      ],
      "metadata": {
        "id": "GrmjhlhqhdPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(123456)\n",
        "test_ind = np.random.randint(y_test.shape[0])\n",
        "test_noisy = x_test[test_ind]\n",
        "test_clear = y_test[test_ind]\n",
        "\n",
        "plt.imshow(test_noisy, cmap='gray')\n",
        "plt.title('Тестовое изображение (шумное)')\n",
        "plt.figure()\n",
        "\n",
        "plt.imshow(test_clear, cmap='gray')\n",
        "plt.title('Тестовое изображение (точное)')\n",
        "plt.figure()"
      ],
      "metadata": {
        "id": "u2TzhbtkhgDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ниже вам пердоставляется возможность построить модель для проведения обешумливания. Поскольку быстрорасчетных численных метрик для оценки точности изображений не так много, как для оценки классификаиции, то вам предоставляется оценить обесшумлевание \"на глаз\".\n",
        "\n",
        "Не забудьте, что автокодировщик должен состоять из Encoder (кодировщика) и Decoder (декодировщика)."
      ],
      "metadata": {
        "id": "XbyRXzILj-BA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "  denoise_model = Sequential()\n",
        "  denoise_model.add(Reshape((28, 28, 1), input_shape=(28, 28)))\n",
        "\n",
        "  # далее input_shape указывать не обязательно\n",
        "  # Постройте свою модель на примере выше. Следует добавлять слои свертки, пулинг и нормализации признаков как приведено в этом комментарии ниже.\n",
        "  # denoise_model.add(Conv2D(*filters_cnt*,\n",
        "  #                         kernel_size=*kernel_size*,\n",
        "  #                         strides=*strides (промежутки между элементами ядра)*,\n",
        "  #                         activation=*функция активации, например - 'relu'*,\n",
        "  #                         padding='same' (Писать именно так! поскольку свертка изменяет размер, а на выходе ожидаем ту же размерность, что и на входе)\n",
        "  #                         ))\n",
        "  # или\n",
        "  # denoise_model.add(BatchNormalization())\n",
        "  # или\n",
        "  # denoise_model.add(MaxPooling2D())\n",
        "  # или\n",
        "  # denoise_model.add(MaxPooling2D())\n",
        "  # или\n",
        "  # denoise_model.add(UpSampling2D())\n",
        "\n",
        "\n",
        "  # encoder\n",
        "  # denoise_model.add(...)\n",
        "  # denoise_model.add(...)\n",
        "  # denoise_model.add(...)\n",
        "\n",
        "  # decoder\n",
        "  # denoise_model.add(...)\n",
        "  # denoise_model.add(...)\n",
        "  # denoise_model.add(...)\n",
        "  # .... и еще слои, сколько посчитаете нужным\n",
        "\n",
        "\n",
        "  # Слой ниже (и последующие слои) менять НЕ надо\n",
        "  denoise_model.add(Conv2D(1, kernel_size=(1, 1), strides=(1, 1), padding='same', activation='relu'))\n",
        "  denoise_model.compile(optimizer='adam',\n",
        "                        loss='mse')\n",
        "  return denoise_model"
      ],
      "metadata": {
        "id": "lhS_Z-PViqyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "denoise_model = build_model()\n",
        "n_epochs = 100\n",
        "\n",
        "history = denoise_model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=n_epochs,\n",
        "    # число примеров, на которых считается градиент:\n",
        "    batch_size=32,\n",
        "    validation_data=(x_test, y_test),\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "plt.plot(range(n_epochs), (history.history['loss']), c='b')\n",
        "plt.plot(range(n_epochs), (history.history['val_loss']), c='g')\n",
        "plt.legend(['Train Loss', 'Validation loss'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w816cN-Jjmn-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}